{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image: 100%|██████████| 49/49 [00:40<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ortomosaico generado y guardado en: ortomosaico.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_images(image_folder):\n",
    "    import os\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(image_folder)):\n",
    "        if filename.endswith((\".JPG\", \".png\", \".tif\")):\n",
    "            img = cv2.imread(os.path.join(image_folder, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "def detect_and_match_features(img1, img2):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    return src_pts, dst_pts\n",
    "\n",
    "def stitch_images(images):\n",
    "    base_image = images[0]\n",
    "    for i in  tqdm(range(1, len(images)), desc=\"Image\"):\n",
    "        src_pts, dst_pts = detect_and_match_features(base_image, images[i])\n",
    "        H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "        height, width, _ = base_image.shape\n",
    "        warped_image = cv2.warpPerspective(images[i], H, (width, height))\n",
    "        mask = (warped_image > 0).astype(np.uint8)\n",
    "        base_image = cv2.add(base_image * (1 - mask), warped_image * mask)\n",
    "    return base_image\n",
    "\n",
    "# Directorio de imágenes\n",
    "image_folder = \"./data/trees-avocado/m3m/campo2/images\"\n",
    "output_path = \"ortomosaico.jpg\"\n",
    "\n",
    "# Cargar imágenes\n",
    "images = load_images(image_folder)\n",
    "\n",
    "# Generar ortomosaico\n",
    "ortomosaico = stitch_images(images)\n",
    "\n",
    "# Guardar el ortomosaico\n",
    "cv2.imwrite(output_path, ortomosaico)\n",
    "print(\"Ortomosaico generado y guardado en:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando imagen 2 de 50...\n",
      "Procesando imagen 3 de 50...\n",
      "Procesando imagen 4 de 50...\n",
      "Procesando imagen 5 de 50...\n",
      "Procesando imagen 6 de 50...\n",
      "Procesando imagen 7 de 50...\n",
      "Procesando imagen 8 de 50...\n",
      "Procesando imagen 9 de 50...\n",
      "Procesando imagen 10 de 50...\n",
      "Procesando imagen 11 de 50...\n",
      "Procesando imagen 12 de 50...\n",
      "Procesando imagen 13 de 50...\n",
      "Procesando imagen 14 de 50...\n",
      "Procesando imagen 15 de 50...\n",
      "Procesando imagen 16 de 50...\n",
      "Procesando imagen 17 de 50...\n",
      "Procesando imagen 18 de 50...\n",
      "Procesando imagen 19 de 50...\n",
      "Procesando imagen 20 de 50...\n",
      "Procesando imagen 21 de 50...\n",
      "Procesando imagen 22 de 50...\n",
      "Procesando imagen 23 de 50...\n",
      "Procesando imagen 24 de 50...\n",
      "Procesando imagen 25 de 50...\n",
      "Procesando imagen 26 de 50...\n",
      "Procesando imagen 27 de 50...\n",
      "Procesando imagen 28 de 50...\n",
      "Procesando imagen 29 de 50...\n",
      "Procesando imagen 30 de 50...\n",
      "Procesando imagen 31 de 50...\n",
      "Procesando imagen 32 de 50...\n",
      "Procesando imagen 33 de 50...\n",
      "Procesando imagen 34 de 50...\n",
      "Procesando imagen 35 de 50...\n",
      "Procesando imagen 36 de 50...\n",
      "Procesando imagen 37 de 50...\n",
      "Procesando imagen 38 de 50...\n",
      "Procesando imagen 39 de 50...\n",
      "Procesando imagen 40 de 50...\n",
      "Procesando imagen 41 de 50...\n",
      "Procesando imagen 42 de 50...\n",
      "Procesando imagen 43 de 50...\n",
      "Procesando imagen 44 de 50...\n",
      "Procesando imagen 45 de 50...\n",
      "Procesando imagen 46 de 50...\n",
      "Procesando imagen 47 de 50...\n",
      "Procesando imagen 48 de 50...\n",
      "Procesando imagen 49 de 50...\n",
      "Procesando imagen 50 de 50...\n",
      "Ortomosaico generado y guardado en: ortomosaico_cultivos.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images(image_folder):\n",
    "    import os\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(image_folder)):\n",
    "        if filename.endswith((\".JPG\", \".png\", \".tif\")):\n",
    "            img = cv2.imread(os.path.join(image_folder, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Convertir a escala de grises\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Aplicar CLAHE para normalizar la iluminación\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(gray)\n",
    "\n",
    "def detect_and_match_features(img1, img2):\n",
    "    # Usar SIFT para detectar puntos clave\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Emparejar características con FLANN\n",
    "    index_params = dict(algorithm=1, trees=5)  # FLANN con KD-Tree\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Aplicar el ratio test de Lowe\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Extraer puntos emparejados\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    return src_pts, dst_pts\n",
    "\n",
    "def stitch_images(images):\n",
    "    # Usar la primera imagen como base\n",
    "    base_image = images[0]\n",
    "    base_image_gray = preprocess_image(base_image)\n",
    "\n",
    "    for i in range(1, len(images)):\n",
    "        print(f\"Procesando imagen {i + 1} de {len(images)}...\")\n",
    "        next_image = images[i]\n",
    "        next_image_gray = preprocess_image(next_image)\n",
    "\n",
    "        # Detectar y emparejar características\n",
    "        src_pts, dst_pts = detect_and_match_features(base_image_gray, next_image_gray)\n",
    "\n",
    "        # Calcular homografía\n",
    "        H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "        # Warpear la siguiente imagen al espacio de la base\n",
    "        height, width, _ = base_image.shape\n",
    "        warped_image = cv2.warpPerspective(next_image, H, (width, height))\n",
    "\n",
    "        # Combinar imágenes suavemente\n",
    "        base_image = np.maximum(base_image, warped_image)\n",
    "\n",
    "    return base_image\n",
    "\n",
    "# Directorio de imágenes\n",
    "image_folder = \"./data/trees-avocado/m3m/campo2/images\"\n",
    "output_path = \"ortomosaico_cultivos.jpg\"\n",
    "\n",
    "# Cargar imágenes\n",
    "images = load_images(image_folder)\n",
    "\n",
    "# Generar ortomosaico\n",
    "ortomosaico = stitch_images(images)\n",
    "\n",
    "# Guardar el ortomosaico\n",
    "cv2.imwrite(output_path, ortomosaico)\n",
    "print(\"Ortomosaico generado y guardado en:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "# Lista de imágenes (reemplaza con tus imágenes)\n",
    "images = [\"img1.jpg\", \"img2.jpg\", \"img3.jpg\"]\n",
    "\n",
    "# Visualizar puntos clave\n",
    "def visualize_keypoints(image, keypoints):\n",
    "    img_with_keypoints = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0))\n",
    "    plt.imshow(cv2.cvtColor(img_with_keypoints, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Puntos clave detectados\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar emparejamientos\n",
    "def visualize_matches(img1, kp1, img2, kp2, matches):\n",
    "    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Emparejamiento de puntos clave\")\n",
    "    plt.show()\n",
    "\n",
    "# Detectar y describir características\n",
    "def detect_and_describe(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "# Emparejar características usando FlannBasedMatcher\n",
    "def match_features_flann(des1, des2):\n",
    "    # Configuración del índice y parámetros del buscador FLANN\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)  # Número de iteraciones para mejorar la precisión\n",
    "\n",
    "    # Crear el objeto FlannBasedMatcher\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    # Encontrar coincidencias\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    print(f\"{len(matches)} matches encontrados\")\n",
    "    # Aplicar ratio test de Lowe\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:  # Umbral de ratio\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "folder_path = \"./data/trees-avocado/m3m/campo2/images/\"\n",
    "\n",
    "jpg_files = glob(f\"{folder_path}/*.JPG\")\n",
    "\n",
    "images = jpg_files\n",
    "\n",
    "# Cargar las imágenes y procesarlas\n",
    "stitched_image = None\n",
    "for i in range(len(images) - 1):\n",
    "    img1 = cv2.imread(images[i], cv2.IMREAD_COLOR)\n",
    "    img2 = cv2.imread(images[i + 1], cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # Convertir a escala de grises\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detectar características\n",
    "    kp1, des1 = detect_and_describe(gray1)\n",
    "    kp2, des2 = detect_and_describe(gray2)\n",
    "    \n",
    "    # Visualizar puntos clave\n",
    "    print(f\"Imagen {i+1}: {len(kp1)} puntos clave detectados\")\n",
    "    visualize_keypoints(img1, kp1)\n",
    "    \n",
    "    # Emparejar características\n",
    "    matches = match_features_flann(des1, des2)\n",
    "    print(f\"Imagen {i+1} - Imagen {i+2}: {len(matches)} emparejamientos buenos encontrados\")\n",
    "    \n",
    "    # Visualizar emparejamientos\n",
    "    visualize_matches(img1, kp1, img2, kp2, matches[:1000])  # Mostrar los primeros 50 emparejamientos\n",
    "    \n",
    "    # Calcular homografía\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    # Transformar la imagen\n",
    "    h, w, _ = img2.shape\n",
    "    if stitched_image is None:\n",
    "        stitched_image = img1\n",
    "    stitched_image = cv2.warpPerspective(stitched_image, H, (w * (i + 2), h))\n",
    "    \n",
    "    # Combinar imágenes\n",
    "    stitched_image[0:h, 0:w] = img2\n",
    "    plt.imshow(cv2.cvtColor(stitched_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Mosaico progresivo después de la imagen {i+2}\")\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "# Guardar el mosaico final\n",
    "cv2.imwrite(\"ortomosaico_flann.jpg\", stitched_image)\n",
    "print(\"Ortomosaico generado y guardado como 'ortomosaico_flann.jpg'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
